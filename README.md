
# Housing Market Analysis Project

## ğŸ  Project Overview

A data-driven analysis of housing market trends using a dataset of 5,555 properties. This project demonstrates end-to-end data analysis skills including data cleaning, exploratory analysis, SQL integration, and visualization.

## ğŸ” Key Skills Demonstrated

- **Data Cleaning & Preprocessing**
- **Exploratory Data Analysis**
- **SQL Database Integration**
- **Statistical Analysis**
- **Data Visualization**
- **Market Segmentation**
- **Business Insights Generation**

## ğŸ“Š Key Findings

- **Location Impact**: Up to 75% price variation between cities, with Blaricum having the highest price/mÂ² (â‚¬6,602)
- **Energy Efficiency Premium**: A++++ labeled properties command a 92% price premium over average
- **Size-Price Correlation**: Strong correlation (0.73) between living space and property price
- **Historical Value**: Properties from the 1930s maintain strong value despite their age
- **Price Segmentation**: Distinct characteristics across Budget, Mid-Range, Premium and Luxury segments

## ğŸ”§ Technical Implementation

1. **Python Analysis**: Statistical analysis and visualization of housing data
2. **SQL Integration**: Database-driven analysis enabling advanced market segmentation
3. **ETL Pipeline**: End-to-end data processing workflow from raw data to insights

## ğŸ“ Project Structure

```
housing-market-analysis/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_data_exploration.ipynb   # Initial dataset exploration
â”‚   â”œâ”€â”€ 2_data_cleaning.ipynb      # Data cleaning and preprocessing
â”‚   â””â”€â”€ 3_analysis.ipynb           # Analysis with Python and SQL
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data.csv               # Original housing dataset
â”‚   â””â”€â”€ processed/                 # Processed data files
â”‚       â””â”€â”€ cleaned_housing_data.csv
â”‚
â”œâ”€â”€ README.md                      # Project overview (this file)
â”œâ”€â”€ report.md                      # Key findings
```

## ğŸš€ Getting Started

1. Clone this repository
2. Install required packages: `pip install -r requirements.txt`
3. Run the notebooks in sequential order:
   - `1_data_exploration.ipynb`
   - `2_data_cleaning.ipynb`
   - `3_analysis.ipynb`

## ğŸ“‹ Key Technologies

- **Python**: pandas, matplotlib, seaborn, scikit-learn
- **Database**: SQLite, SQLAlchemy
- **Visualization**: Matplotlib, Seaborn

## ğŸ“ Full Report

For the detailed analysis, findings and recommendations, see the full report on report.md.

---

**Author**: [Hanh Nguyen] | **Contact**: [hanhprovt2002@gmail.com] | **LinkedIn**: [https://www.linkedin.com/in/huu-hanh-nguyen/]
